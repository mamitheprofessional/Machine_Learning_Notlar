{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# değişken türleri :\n",
    "\n",
    "sayısal değişken\n",
    "\n",
    "kategorik değişken (ikiye ayrılır) \n",
    "nominal = kadın-erkek, futbol takımları gibi sınıflar arasında fark olmayan değişkenlerdir\n",
    "ordinal = yaş, eğitim seviyesi gibi sınıflar arasında fark olan sıralı değişkenlerdir \n",
    "\n",
    "bağımlı değişken (target, dependent, output, response)\n",
    "bağımsız değişken (feature, independent, input, column, predictor, explanatory)\n",
    "\n",
    "karar verirken şuna bakılır verisetindeki bağımlı değişken sayısal ise ozaman problem regresyon problemidir \n",
    "örneğin:\n",
    "-    Bir evin fiyatını tahmin etmek (Bağımlı değişken: fiyat (sürekli bir sayı))\n",
    "-    Bir hastanın kan basıncını tahmin etmek (Bağımlı değişken: kan basıncı değeri)\n",
    "-    Bir öğrencinin sınavdan alacağı puanı tahmin etmek (Bağımlı değişken: puan (0-100 arası bir sayı))\n",
    "\n",
    "Eğer bağımlı değişken kategorik olsaydı, bu bir sınıflandırma problemi olurdu.\n",
    "Örnekler:\n",
    "\n",
    "-    Bir hastalığın var olup olmadığını belirleme (Bağımlı değişken: hasta (1) / değil (0))\n",
    "-    E-postanın spam olup olmadığını belirleme (Bağımlı değişken: spam / spam değil)\n",
    "-    Bir öğrencinin sınıfı geçip geçmeyeceğini tahmin etme (Bağımlı değişken: geçti / kaldı)\n",
    "\n",
    "---\n",
    "\n",
    "makina öğrenmeside 3 e ayrılır\n",
    "denetimli öğrenme (supervized learning)\n",
    "denetimsiz öğrenme (unsupervised learning)\n",
    "pekiştirmeli öğrenme (reinforcement learning)\n",
    "\n",
    "\n",
    "Denetimli öğrenme: verisetinde bağımlı değişken varsa target varsa etiket varsa bu denetimli öğrenme problemidir\n",
    "yani bağımlı ve bağımsız arasındaki ilişki öğreniliyordur\n",
    "\n",
    "    Bir hastanın kan tahlil sonuçlarından hastalığının olup olmadığını tahmin etmek (etiket = hasta/hasta değil)\n",
    "    Bir resmin kedi mi köpek mi olduğunu belirlemek (etiket = kedi/köpek)\n",
    "\n",
    "Denetimsiz öğrenme:\n",
    "mesela verisetinde müşteriler ile ilgili bilgiler verilmiş ama bir target yok bunları benzerliklere göre kümelere koyarsın\n",
    "    Müşteri segmentasyonu (alışveriş alışkanlıklarına göre benzer müşterileri gruplamak, ama elimizde müşteri grubu etiketi yok)\n",
    "    Bir sosyal medya platformunda benzer kullanıcıları bulup öneriler yapmak\n",
    "\n",
    "Sınıflandırma ve Regresyon → Denetimli Öğrenme\n",
    "\n",
    "    Eğer model, belirli etiketlere (örneğin hastalık var/yok) veya sayısal tahminlere (örneğin ev fiyatı) odaklanıyorsa, denetimli öğrenmedir.\n",
    "\n",
    "Kümeleme ve Boyut İndirgeme → Denetimsiz Öğrenme\n",
    "\n",
    "    Eğer model veriyi kendi içinde analiz edip doğal gruplamalar yapıyorsa (örneğin müşteri segmentasyonu), denetimsiz öğrenmedir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# regresyon modellerinde başarı değerlendirme\n",
    "\n",
    "MSE, RMSE ve MAE, regresyon modellerinin doğruluğunu (hata miktarını) ölçmek için kullanılan hata metrikleridir. Bunlar, modelin tahmin ettiği değerler ile gerçek değerler arasındaki farkı ölçerek, modelin ne kadar iyi çalıştığını değerlendirir.\n",
    "\n",
    "mse (min squared error) = gerçek değerlerle tahmin edilen bütün değerleri çıkartıp eksi olmaması için karesini alıp ortalamasını aldığın değerdir bu modelin tahmin başarsırını gösterir ne kadar az ise okadar az hata yapılmış demektir\n",
    "\n",
    "✅ Hataları kare aldığı için büyük hatalar daha fazla cezalandırılır.\n",
    "✅ Sürekli değer tahmini yapan regresyon modellerinde yaygın olarak kullanılır.\n",
    "❌ Negatif veya pozitif farkları sıfırlamaz ama karesini aldığı için büyük hatalara çok duyarlıdır.\n",
    "❌ Birim kareli (örneğin, hata cm ise MSE cm² olur), yorumlaması zor olabilir.\n",
    "\n",
    "📌 Örnek:\n",
    "Gerçek değerler: [3, 5, 2]\n",
    "Tahminler: [2, 4, 3]\n",
    "Farklar: [1, 1, -1]\n",
    "Kareler: [1, 1, 1]\n",
    "MSE = (1+1+1) / 3 = 1.0\n",
    "\n",
    "rmse sadece karekök alarak kareden kurtadığımız hali\n",
    "\n",
    "MAE(Mean Absolute Error - Ortalama Mutlak Hata), hataların mutlak değerlerinin ortalamasıdır. MSE ve RMSE'den farklı olarak, karesini almaz, doğrudan farkların mutlak değerini alır.\n",
    "MAE, hataların mutlak değerlerinin ortalamasıdır. MSE ve RMSE'den farklı olarak, karesini almaz, doğrudan farkların mutlak değerini alır.\n",
    "✅ MSE ve RMSE'den daha az duyarlıdır, büyük hataları fazla cezalandırmaz.\n",
    "✅ Gerçek değerlerle aynı birime sahiptir ve yorumlaması kolaydır.\n",
    "❌ RMSE kadar büyük hatalara duyarlı değildir.\n",
    "\n",
    "📌 Örnek:\n",
    "Gerçek değerler: [3, 5, 2]\n",
    "Tahminler: [2, 4, 3]\n",
    "Farkların mutlak değeri: [1, 1, 1]\n",
    "MAE = (1+1+1) / 3 = 1.0\n",
    "\n",
    "geri kalan hata ölçer metrikler bunlar\n",
    "R² (R-Kare - Belirleme Katsayısı)\n",
    "Adjusted R² (Düzeltilmiş R-Kare)\n",
    "MAPE (Mean Absolute Percentage Error - Ortalama Mutlak Yüzde Hatası)\n",
    "MSLE (Mean Squared Logarithmic Error - Ortalama Logaritmik Kare Hatası)\n",
    "\n",
    "✅ Büyük hatalara duyarlı bir metrik istersen → RMSE veya MSE kullan.\n",
    "✅ Daha anlaşılır ve dengeli bir metrik istersen → MAE kullan.\n",
    "✅ Modelin başarı yüzdesini görmek istersen → R² veya Adjusted R² kullan.\n",
    "✅ Hata yüzdesi görmek istersen → MAPE kullan.\n",
    "✅ Özellikle büyük değerlerde hata analiz etmek istersen → MSLE kullan.\n",
    "\n",
    "daha başkada var\n",
    "Huber Loss (Huber Hatası)\n",
    "Log-Cosh Loss (Logaritmik Cosh Hatası)\n",
    "Medyan Mutlak Hata (Median Absolute Error - MedAE)\n",
    "SMMAPE (Symmetric Mean Absolute Percentage Error - Simetrik Ortalama Mutlak Yüzde Hatası)\n",
    "Relative Absolute Error (RAE - Göreceli Mutlak Hata)\n",
    "Relative Squared Error (RSE - Göreceli Kare Hata)\n",
    "Mean Bias Deviation (MBD - Ortalama Sapma Hatası)\n",
    "Durbin-Watson Testi (Otokorelasyon Testi - DW Testi)\n",
    "\n",
    "\n",
    "\n",
    "bunlarda sınıflandırma için\n",
    "    Accuracy (Doğruluk) = doğruyu tahminlerin sayısını tüm tahmin sayısına bölüyor\n",
    "    Precision (Kesinlik)\n",
    "    Recall (Duyarlılık, Özgülük)\n",
    "    F1-Score\n",
    "    Specificity (Özgüllük, Negatif Sınıf Duyarlılığı)\n",
    "    ROC-AUC (Receiver Operating Characteristic - Area Under Curve)\n",
    "    PR-AUC (Precision-Recall Eğrisi Altındaki Alan)\n",
    "    Log Loss (Lojistik Kayıp)\n",
    "    Matthews Correlation Coefficient (MCC - Matthews Korelasyon Katsayısı)\n",
    "    Cohen’s Kappa (Cohen’in Kappa Katsayısı)\n",
    "    Hamming Loss\n",
    "    Jaccard Score\n",
    "\n",
    "## 📊 Regresyon Metrikleri\n",
    "\n",
    "| **Metrik**                      | **Açıklama**                                                                 | **Artılar**                                                         | **Eksiler**                                                         |\n",
    "|----------------------------------|-----------------------------------------------------------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|\n",
    "| **MSE (Mean Squared Error)**     | Hata karelerinin ortalaması, büyük hataları daha fazla cezalandırır.       | - Büyük hatalar daha fazla cezalandırılır.                         | - Hataların büyüklüğü yüzünden büyük hatalar aşırı etkili olabilir. |\n",
    "| **RMSE (Root Mean Squared Error)** | MSE’nin karekökü, hatayı orijinal ölçeğinde gösterir.                      | - Hata oranını orijinal ölçeğinde sunar.                           | - MSE’ye benzer şekilde büyük hataları fazla cezalandırır.        |\n",
    "| **MAE (Mean Absolute Error)**    | Mutlak hataların ortalaması, daha az cezalandırıcıdır.                     | - Büyük hatalar üzerinde fazla etkisi yoktur.                      | - Modelin tüm hatalarını eşit şekilde değerlendirir, büyük hatalara duyarsızdır. |\n",
    "| **R² (R-Kare, Determination Coefficient)** | Modelin bağımsız değişkenlerle ne kadar iyi açıklandığını gösterir.       | - Modelin ne kadar başarılı olduğunu net bir şekilde gösterir.    | - Aşırı öğrenme (overfitting) ile yanıltıcı olabilir.             |\n",
    "| **Adjusted R² (Düzeltilmiş R-Kare)** | R²’ye göre değişken sayısını da dikkate alarak düzeltilmiş versiyonu.     | - Fazla bağımsız değişkenin modelin başarısız görünmesini engeller. | - Küçük veri setlerinde yanıltıcı olabilir.                      |\n",
    "| **MAPE (Mean Absolute Percentage Error)** | Hata oranını yüzde olarak ifade eder. Özellikle iş dünyasında kullanılır. | - Kolayca yorumlanabilir ve yaygın olarak kullanılır.              | - Sıfıra yakın değerler sorun yaratabilir.                         |\n",
    "| **MSLE (Mean Squared Logarithmic Error)** | Küçük ve büyük hatalar arasındaki farkı azaltmak için logaritmik ölçek kullanır. | - Küçük değerler üzerindeki hataları daha iyi denetler.            | - Yüksek değerli verilerde performans kaybı olabilir.              |\n",
    "| **Huber Loss**                   | MSE ile MAE'nin birleşimidir, küçük hatalar için kareli kayıp, büyük hatalar için mutlak kayıp kullanır. | - Hem büyük hem küçük hatalar üzerinde dengeli bir etkisi vardır. | - Parametre seçimi gerektirir (delta).                             |\n",
    "| **Quantile Loss**                | Regresyon için belirli bir yüzdelik dilim (quantile) üzerinde kayıp hesaplar. | - Özellikle asimetrik hata dağılımları için kullanışlıdır.        | - Hesaplama karmaşıklığı ve parametre ayarları gerektirir.         |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Sınıflandırma Metrikleri\n",
    "\n",
    "| **Metrik**                      | **Açıklama**                                                                 | **Artılar**                                                         | **Eksiler**                                                         |\n",
    "|----------------------------------|-----------------------------------------------------------------------------|--------------------------------------------------------------------|--------------------------------------------------------------------|\n",
    "| **Accuracy (Doğruluk)**          | Toplam doğru tahminlerin oranı.                                              | - Basit ve kolay anlaşılır.                                        | - Dengesiz sınıflar için yanıltıcı olabilir.                       |\n",
    "| **Precision (Kesinlik)**         | Pozitif tahminlerin ne kadarının gerçekten pozitif olduğunu gösterir.       | - Özellikle yanlış pozitiflerin istenmediği durumlarda faydalıdır. | - Düşük sınıf örnekleriyle düşük olabilir.                         |\n",
    "| **Recall (Duyarlılık, Sensitivity)** | Gerçek pozitiflerin ne kadarını doğru tahmin ettiğini gösterir.              | - Yanlış negatifleri önler ve yüksek duyarlılık sağlar.            | - Yanlış pozitifleri artırabilir.                                  |\n",
    "| **F1-Score**                     | Precision ve Recall’un harmonik ortalaması.                                  | - Hem Precision hem Recall dikkate alınır.                         | - Tek başına yeterli olmayabilir, genellikle diğer metriklerle birlikte kullanılır. |\n",
    "| **ROC-AUC (Receiver Operating Characteristic - Area Under Curve)** | Modelin sınıfları ayırt etme yeteneğini ölçer.                            | - Düşük sınıflar için bile geçerli sonuçlar verir.                 | - Farklı sınıf dengesizliklerinde yanıltıcı olabilir.              |\n",
    "| **Log Loss (Logaritmik Kayıp)**  | Modelin olasılık tahminlerinin ne kadar hatalı olduğunu ölçer.              | - Modelin olasılık tahminlerine duyarlıdır.                        | - Sınıf dengesizliği sorun yaratabilir.                             |\n",
    "| **Matthews Correlation Coefficient (MCC)** | Dengeli sınıflandırma performansını ölçmek için kullanılır.               | - Dengesiz veri setlerinde daha güvenilir sonuç verir.             | - Anlaması ve uygulaması zor olabilir.                            |\n",
    "| **Confusion Matrix (Karışıklık Matrisi)** | Sınıflandırma hatalarının detaylı görsel gösterimi.                         | - Modelin hatalarını çok daha net gösterir.                        | - Yalnızca diğer metriklerle birlikte yorumlanmalıdır.             |\n",
    "| **Cohen's Kappa**                | Modelin doğruluğunu rastgele tahminlerle karşılaştırarak ölçer.              | - Sınıflar arası dengesizliğin etkisini en aza indirir.            | - Hesaplaması karmaşık olabilir.                                   |\n",
    "| **Specificity (Özgüllük)**       | Gerçek negatiflerin ne kadarını doğru tahmin ettiğini gösterir.              | - Yanlış pozitiflerin kontrolü için faydalıdır.                     | - Genellikle diğer metriklerle birlikte değerlendirilmelidir.     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Doğrulama Yöntemleri\n",
    "\n",
    "1️⃣ Hold-Out Validation (Ayrılmış Veri Seti Yöntemi)\n",
    "2️⃣ K-Fold Cross Validation (K-Katlı Çapraz Doğrulama)\n",
    "3️⃣ Stratified K-Fold Cross Validation (Katmanlı K-Katlı Çapraz Doğrulama)\n",
    "4️⃣ Leave-One-Out Cross Validation (LOOCV - Birini Bırak Çapraz Doğrulama)\n",
    "5️⃣ Leave-P-Out Cross Validation (LPOCV - P’sini Bırak Çapraz Doğrulama)\n",
    "6️⃣ Time Series Cross Validation (Zaman Serisi Çapraz Doğrulama - Rolling Window)\n",
    "7️⃣ Bootstrapping (Örnekleme ile Doğrulama)\n",
    "1️⃣ Hold-Out Validation (Ayrılmış Veri Seti Yöntemi)\n",
    "\n",
    "En basit doğrulama yöntemidir. Veri, eğitim (train) ve test seti olarak ayrılır.\n",
    "\n",
    "    Genellikle %70 eğitim – %30 test veya %80 eğitim – %20 test şeklinde ayrılır.\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Hızlı ve kolaydır.\n",
    "✔️ Küçük veri setlerinde bile kullanılabilir.\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Verinin tek bir bölümü kullanıldığı için modelin genelleme yeteneği düşük olabilir.\n",
    "❌ Modelin performansı veri setinin nasıl bölündüğüne bağlıdır.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Büyük veri setlerinde tercih edilebilir.\n",
    "\n",
    "2️⃣ K-Fold Cross Validation (K-Katlı Çapraz Doğrulama)\n",
    "\n",
    "Veri, K eşit parçaya (folds) bölünür.\n",
    "\n",
    "    Model K-1 fold üzerinde eğitilir, kalan 1 fold test için kullanılır.\n",
    "    Bu işlem K kez tekrarlanır ve sonuçların ortalaması alınır.\n",
    "\n",
    "📌 Örnek:\n",
    "\n",
    "    K=5 için veri 5 parçaya bölünür.\n",
    "    1. iterasyon → 1. parça test, diğerleri eğitim\n",
    "    2. iterasyon → 2. parça test, diğerleri eğitim\n",
    "    ...\n",
    "    5. iterasyon → 5. parça test, diğerleri eğitim\n",
    "    Sonuçlar ortalaması alınarak modelin başarısı belirlenir.\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Modelin genelleme yeteneğini daha iyi ölçer.\n",
    "✔️ Hold-Out yöntemine göre daha güvenilirdir.\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Eğitim süresi uzundur, çünkü model K kez eğitilir.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Orta ve büyük boyutlu veri setlerinde tercih edilir.\n",
    "    Modelin farklı veri bölümlerinde nasıl çalıştığını görmek istenildiğinde kullanılır.\n",
    "\n",
    "3️⃣ Stratified K-Fold Cross Validation (Katmanlı K-Katlı Çapraz Doğrulama)\n",
    "\n",
    "K-Fold Cross Validation’ın gelişmiş versiyonudur.\n",
    "\n",
    "    Sınıf oranlarını koruyarak veri bölünür.\n",
    "    Özellikle dengesiz veri setlerinde (örneğin %90 \"Evet\" - %10 \"Hayır\") kullanılır.\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Dengesiz sınıf dağılımı olan veri setlerinde daha iyi sonuç verir.\n",
    "✔️ K-Fold’un avantajlarına sahiptir.\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Eğitim süresi uzundur.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Sınıflar arasında dengesizlik varsa (örneğin sahtekarlık tespiti, tıbbi teşhis vb.)\n",
    "\n",
    "4️⃣ Leave-One-Out Cross Validation (LOOCV - Birini Bırak Çapraz Doğrulama)\n",
    "\n",
    "Veri setindeki her bir örnek, sırasıyla test verisi olarak kullanılır.\n",
    "\n",
    "    Eğer veri setinde N örnek varsa, model tam olarak N kez eğitilir.\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Modelin her veri noktası için test edilmesini sağlar.\n",
    "✔️ Küçük veri setlerinde çok iyi performans verir.\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Çok zaman alır (büyük veri setlerinde uygulanması zordur).\n",
    "❌ Overfitting riski vardır.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Küçük veri setlerinde kullanılır.\n",
    "\n",
    "5️⃣ Leave-P-Out Cross Validation (LPOCV - P’sini Bırak Çapraz Doğrulama)\n",
    "\n",
    "LOOCV’nin genişletilmiş versiyonudur.\n",
    "\n",
    "    Her iterasyonda P tane test örneği bırakılır, kalan veri ile model eğitilir.\n",
    "    LOOCV özel bir durumudur (P=1 ise LOOCV olur).\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Modelin farklı kombinasyonlarla test edilmesini sağlar.\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Büyük veri setlerinde çok fazla hesaplama gerektirir.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Küçük veri setlerinde LOOCV yerine daha esnek bir yöntem olarak tercih edilebilir.\n",
    "\n",
    "6️⃣ Time Series Cross Validation (Zaman Serisi Çapraz Doğrulama - Rolling Window)\n",
    "\n",
    "Zaman serisi verileri için özel bir doğrulama yöntemidir.\n",
    "\n",
    "    Geçmiş veriler kullanılarak model eğitilir, gelecekteki veriler test edilir.\n",
    "    Veri geçmişten geleceğe doğru kaydırılır (rolling window).\n",
    "\n",
    "📌 Örnek:\n",
    "\n",
    "    1. adım: 1-100. verilerle eğitim, 101-110. verilerle test\n",
    "    2. adım: 1-110. verilerle eğitim, 111-120. verilerle test\n",
    "    Devam eder...\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Zaman bağımlı veriler için uygundur (örneğin finans, hava tahmini).\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Hesaplama maliyeti yüksektir.\n",
    "❌ Veri noktaları bağımsız olmadığı için bazı hatalara yol açabilir.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Zaman serisi problemlerinde (örneğin, borsa tahmini).\n",
    "\n",
    "7️⃣ Bootstrapping (Örnekleme ile Doğrulama)\n",
    "\n",
    "Veri setinden rastgele örnekler çekerek modelin doğruluğunu test eden bir yöntemdir.\n",
    "\n",
    "    Tek bir eğitim/test bölümü yerine, birden fazla kez örnekleme yapılır.\n",
    "\n",
    "📌 Örnek:\n",
    "\n",
    "    1000 verilik veri setinden rastgele 800 veri eğitim, 200 veri test için seçilir.\n",
    "    Bu işlem birçok kez tekrarlanır.\n",
    "\n",
    "🔹 Avantajları:\n",
    "✔️ Küçük veri setlerinde modelin daha iyi değerlendirilmesini sağlar.\n",
    "✔️ Veri setindeki çeşitliliği artırır.\n",
    "\n",
    "🔹 Dezavantajları:\n",
    "❌ Rastgele seçilen veri nedeniyle bazı örnekler hiç test edilmez.\n",
    "\n",
    "🔹 Ne Zaman Kullanılır?\n",
    "\n",
    "    Veri seti küçükse ve doğrulama için daha fazla veri üretmek isteniyorsa.\n",
    "\n",
    "| **Yöntem**                       | **Kullanım Durumu**                                      |\n",
    "|----------------------------------|---------------------------------------------------------|\n",
    "| **Hold-Out**                     | Büyük veri setlerinde hızlı bir yöntem                 |\n",
    "| **K-Fold Cross Validation**       | Genel amaçlı, orta-büyük veri setlerinde ideal         |\n",
    "| **Stratified K-Fold**             | Dengesiz veri setlerinde kullanılır                    |\n",
    "| **LOOCV**                         | Küçük veri setlerinde kullanılır                       |\n",
    "| **LPOCV**                         | LOOCV’nin daha esnek hali, küçük veri setlerinde      |\n",
    "| **Time Series Cross Validation**  | Zaman serisi analizlerinde                            |\n",
    "| **Bootstrapping**                 | Küçük veri setlerinde, daha fazla test senaryosu oluşturmak için |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pngs/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overfittinge düştüğümüzü nasıl anlarız ?\n",
    "\n",
    "![alt text](pngs/2.png)\n",
    "\n",
    "bu görsel üzerinden eğer test seti ile eğitim seti arasında çatallanmayı olursa yani optimum noktadan sonrası overfittingdir\n",
    "model karmaşıklığı doğrusal modellerinde farklı ağaç modellerinde farklı sinir ağlarına göre farklı olur\n",
    "doğrusal modellerde mx + n de hassasiyeti artırmak ve daha iyi gözlem yapmak için x'2 x'3 gibi değerler kullanılır\n",
    "ağaç yöntemlerinde ise daha fazla dallanma yaparak karmaşıklık arttırılır\n",
    "yani sözün özü model karmaşıklığı arttıkça overfittinginde önüne geçeriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lineer regresyona giriş\n",
    "\n",
    "Ŷ = wx + b\n",
    "Ŷ: Modelin tahmin ettiği çıktı (bağımlı değişken).\n",
    "w: Bağımsız değişken x'in model üzerindeki etkisi.\n",
    "x: Modelin kullandığı girdi (bağımsız değişken).\n",
    "b: Sabit terim, y eksenindeki kesişim noktası.\n",
    "\n",
    "doğrunun konumunu yönünü belirleyen şey aslında mse formülü\n",
    "regresyone modellerinin tahmininde en minimal hatayı bulabilmek için mse rmse mae gibi hata metrikleri kullanılır \n",
    "sonrasında en az hata payını yakalayana kadar optimizasyon yapacağız\n",
    "Gradyan İnişi (Gradient Descent)\n",
    "Adam (Adaptive Moment Estimation)\n",
    "RMSprop (Root Mean Square Propagation)\n",
    " gibi gibi birçok optimizasyon yöntemi var\n",
    " | **Optimizasyon Algoritması** | **Avantajı** | **Hangi Durumlarda Kullanılır?** |\n",
    "|-----------------------------|-------------|--------------------------------|\n",
    "| **Gradient Descent (GD)** | Basit, etkili | Küçük veri setleri, temel modeller |\n",
    "| **SGD (Stochastic GD)** | Hızlı ama gürültülü | Büyük veri setleri, online öğrenme |\n",
    "| **Mini-batch GD** | Hız ve doğruluk dengesi | Orta büyüklükte veri setleri |\n",
    "| **Adam** | Otomatik öğrenme oranı ayarı | Derin öğrenme modelleri |\n",
    "| **RMSprop** | Öğrenme oranını otomatik ayarlar | Gürültülü veriler, istikrarlı öğrenme |\n",
    "| **L-BFGS** | Daha az iterasyonla optimizasyon | Küçük veri setleri, regresyon modelleri |\n",
    "\n",
    "\n",
    "mesela gradient descent ağırlık değerleriyle oynayan kısmü tirevli denklemli formülü var\n",
    "ağırlık - korkunç formül = gradient descent \n",
    "her seferinde yeni ağırlık atıyor sonra tahmin hata payına bakıyor düşütmü düşmedimi diye\n",
    "\n",
    "\n",
    "# gradient descent\n",
    "amaç hatayı minimize etmek ve grafikte optimum noktayı bulmaya çalışmak\n",
    "\n",
    "Başlangıç ağırlığı seçilir. (rastgele bir noktadan)\n",
    "Tahmin yapılır → (hypothesis)\n",
    "Gerçek sonuçla karşılaştırılır → (loss function)\n",
    "Hata fonksiyonunun türevi alınır → (gradyan)\n",
    "Gradyanın ters yönünde ağırlık güncellenir.\n",
    "Hata tekrar hesaplanır → Düşüyor mu diye kontrol edilir.\n",
    "Yeterince küçük bir hata elde edilene kadar döngü tekrar eder.\n",
    "\n",
    "learning rate ile artan veya azalan ağırlık noktasının sıçrayış değeri bulunur\n",
    "örnek 10 birim art veya azal dersek optimum nokta biraz uzaklaşabilir 1 birim art veya azal dersek daha iyi optimum değer bulunabilir\n",
    "ama 10 birim hızlı iken 1 birimlik rate değeri daha yavaş öğrenir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
